["{\"transientOutputs\":false,\"transientCellMetadata\":{\"breakpointMargin\":true,\"id\":false,\"metadata\":false,\"attachments\":false},\"transientDocumentMetadata\":{\"cells\":true,\"indentAmount\":true},\"cellContentMetadata\":{\"attachments\":true}}","{\"cells\":[{\"cellKind\":1,\"language\":\"markdown\",\"metadata\":{\"metadata\":{},\"id\":\"b39dd5f8\"},\"outputs\":[],\"source\":\"# ModernBERT Text Guardrail: Training Pipeline\\n\\nThis notebook provides the complete pipeline to train a text classification model to detect malicious prompts (prompt injection, jailbreaks). It uses a combined dataset of malicious and benign text to fine-tune a `distilbert-base-uncased` model.\",\"internalMetadata\":{\"internalId\":\"7ca9be7f\"}},{\"cellKind\":1,\"language\":\"markdown\",\"metadata\":{\"metadata\":{},\"id\":\"eed9e98a\"},\"outputs\":[],\"source\":\"## Step 1: Install Required Libraries\",\"internalMetadata\":{\"internalId\":\"6596a87a\"}},{\"cellKind\":2,\"language\":\"python\",\"metadata\":{\"execution_count\":null,\"metadata\":{},\"id\":\"c08943c0\"},\"outputs\":[],\"source\":\"!pip install -q transformers datasets accelerate scikit-learn pandas\",\"internalMetadata\":{\"internalId\":\"0bcc79ce\"}},{\"cellKind\":1,\"language\":\"markdown\",\"metadata\":{\"metadata\":{},\"id\":\"4eb81cd8\"},\"outputs\":[],\"source\":\"## Step 2: Create the Labeled Dataset\\n\\nThis cell combines a dataset of malicious prompts with a dataset of benign text to create the final training data.\",\"internalMetadata\":{\"internalId\":\"05d8034a\"}},{\"cellKind\":2,\"language\":\"python\",\"metadata\":{\"execution_count\":null,\"metadata\":{},\"id\":\"27647832\"},\"outputs\":[],\"source\":\"from datasets import load_dataset, Dataset, concatenate_datasets\\nimport pandas as pd\\n\\n# 1. Load the malicious and benign datasets\\nprint(\\\"Loading datasets...\\\")\\nmalicious_ds = load_dataset(\\\"deepset/prompt-injections\\\", split=\\\"train\\\")\\nbenign_ds = load_dataset(\\\"ag_news\\\", split=\\\"train\\\")\\n\\n# 2. Prepare and label the datasets\\n# Malicious data (label = 1)\\nmalicious_df = malicious_ds.to_pandas()\\nmalicious_df['label'] = 1\\nmalicious_df = malicious_df[['text', 'label']]\\n\\n# Benign data (label = 0)\\nbenign_df = benign_ds.to_pandas()\\nbenign_df['label'] = 0\\nbenign_df = benign_df[['text', 'label']]\\n\\n# Balance the dataset by taking a sample of benign data\\nnum_malicious_samples = len(malicious_df)\\nbenign_df = benign_df.sample(n=num_malicious_samples * 2, random_state=42)\\n\\n# 3. Combine them into a single dataset\\ncombined_df = pd.concat([malicious_df, benign_df], ignore_index=True)\\nfinal_dataset = Dataset.from_pandas(combined_df)\\n\\n# 4. Shuffle the dataset\\nfinal_dataset = final_dataset.shuffle(seed=42)\\n\\nprint(\\\"\\\\n--- Final Dataset Created ---\\\")\\nprint(final_dataset)\",\"internalMetadata\":{\"internalId\":\"07847655\"}}],\"metadata\":{\"metadata\":{\"language_info\":{\"name\":\"python\"}},\"nbformat\":4,\"nbformat_minor\":5}}"]